[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataSHIELD Workshop",
    "section": "",
    "text": "Introduction\nThis website hosts the materials and exercises for the DataSHIELD workshop at the Institut Català d’Oncologia (ICO).\nOn it you will find reading materials, setup tutorials, workshop indications and practical exercises.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workshop Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "DataSHIELD Workshop",
    "section": "Getting Started",
    "text": "Getting Started\nAll practical exercises will be conducted using the public Opal demo server. This server provides a fully functional DataSHIELD environment with sample datasets that workshop participants can use to replicate the examples.\nLogin credentials for the demo server are:\n\nUsername: dsuser\nPassword: P@ssw0rd",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workshop Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "DataSHIELD Workshop",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore starting, make sure to install the required R packages in your local machine:\n\ninstall.packages('DSI')\ninstall.packages('DSOpal')\ninstall.packages('dsBaseClient', repos='http://cran.obiba.org', type='source', dependencies=TRUE)\ninstall.packages('metafor')\ndevtools::install_github('lifecycle-project/ds-helper')\ndevtools::install_github('isglobal-brge/dsOMOPClient')\ndevtools::install_github('isglobal-brge/dsOMOPHelper')",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workshop Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "DataSHIELD Workshop",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\nTime\nTopic\n\n\n\n\n09:00\nWelcome\n\n\n09:15 - 09:45\nIntroduction to DataSHIELD and OPAL\n\n\n09:45 - 11:00\nWorkshop DataSHIELD data analysis + Exercise\n\n\n11:00 - 11:30\nBreak\n\n\n11:30 - 12:00\nIntroduction to OMOP and dsOMOP and extensions (dsHelper and dsOMOP.oracle)\n\n\n12:00 - 12:30\nWorkshop dsOMOP cancer data analysis from OMOP database",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workshop Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "DataSHIELD Workshop",
    "section": "Credits",
    "text": "Credits\nMaterial developed at the Bioinformatics Research Group in Epidemiology (BRGE) of the Barcelona Institute for Global Health (ISGlobal) by Juan R González and David Sarrat González.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Workshop Introduction</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html",
    "href": "chapters/datashield.html",
    "title": "DataSHIELD Workshop",
    "section": "",
    "text": "INFORMATION FOR NEWCOMERS TO RSTUDIO NOTEBOOKS:\nThis is an R Markdown Notebook. When you execute code within the notebook, the results appear beneath the code. Here you can download the .Rmd file to reproduce this bookdown using RStudio (in case the download does not work, right click on the link and select “Save link as…”). You can also copy and paste the R code available in every step.\nTry executing this chunk by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter.\nThe plan for this lesson is as follows:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#installing-datashield",
    "href": "chapters/datashield.html#installing-datashield",
    "title": "DataSHIELD Workshop",
    "section": "Installing DataSHIELD",
    "text": "Installing DataSHIELD\nFirstly: check whether we have the right R packages installed to run DataSHIELD: using the very helpful devtools package, we’ll use the “Session info” command:\n\ninstall.packages(\"devtools\")\nlibrary(devtools)\ndevtools::session_info()\n\nWe are missing some of the necessary packages: “DSI”, “DSOpal” and “dsBaseClient”.\n\ninstall.packages('DSI')\ninstall.packages('DSOpal')\ninstall.packages('dsBaseClient', repos='http://cran.obiba.org', type='source', dependencies=TRUE)\ninstall.packages('metafor')\ndevtools::install_github('lifecycle-project/ds-helper')\n\nRemember to load them into this R session using “library()” command:\n\nlibrary(DSI)\n\nLoading required package: progress\n\n\nLoading required package: R6\n\nlibrary(DSOpal)\n\nLoading required package: opalr\n\n\nLoading required package: httr\n\nlibrary(dsBaseClient)\nlibrary(dsHelper)\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.6-0). For an\nintroduction to the package please type: help(metafor)\n\n\nCheck that they have now been added:\n\ndevtools::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       macOS Sonoma 14.5\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       Europe/Madrid\n date     2025-01-08\n pandoc   3.6 @ /opt/homebrew/bin/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version    date (UTC) lib source\n backports      1.5.0      2024-05-23 [1] CRAN (R 4.4.0)\n boot           1.3-31     2024-08-28 [1] CRAN (R 4.4.2)\n cachem         1.1.0      2024-05-16 [1] CRAN (R 4.4.0)\n checkmate      2.3.2      2024-07-29 [1] CRAN (R 4.4.0)\n cli            3.6.3      2024-06-21 [1] CRAN (R 4.4.0)\n crayon         1.5.3      2024-06-20 [1] CRAN (R 4.4.0)\n data.table     1.16.4     2024-12-06 [1] CRAN (R 4.4.1)\n devtools       2.4.5      2022-10-11 [1] CRAN (R 4.4.0)\n digest         0.6.37     2024-08-19 [1] CRAN (R 4.4.1)\n dplyr          1.1.4      2023-11-17 [1] CRAN (R 4.4.0)\n dsBaseClient * 6.3.0      2025-01-08 [1] local\n dsHelper     * 1.0.3.9000 2025-01-08 [1] Github (lifecycle-project/ds-helper@f5ed1e6)\n DSI          * 1.7.1      2024-11-03 [1] CRAN (R 4.4.1)\n DSOpal       * 1.4.0      2022-10-06 [1] CRAN (R 4.4.0)\n ellipsis       0.3.2      2021-04-29 [1] CRAN (R 4.4.0)\n evaluate       1.0.1      2024-10-10 [1] CRAN (R 4.4.1)\n fastmap        1.2.0      2024-05-15 [1] CRAN (R 4.4.0)\n forcats        1.0.0      2023-01-29 [1] CRAN (R 4.4.0)\n fs             1.6.5      2024-10-30 [1] CRAN (R 4.4.1)\n generics       0.1.3      2022-07-05 [1] CRAN (R 4.4.0)\n glue           1.8.0      2024-09-30 [1] CRAN (R 4.4.1)\n haven          2.5.4      2023-11-30 [1] CRAN (R 4.4.0)\n hms            1.1.3      2023-03-21 [1] CRAN (R 4.4.0)\n htmltools      0.5.8.1    2024-04-04 [1] CRAN (R 4.4.0)\n htmlwidgets    1.6.4      2023-12-06 [1] CRAN (R 4.4.0)\n httpuv         1.6.15     2024-03-26 [1] CRAN (R 4.4.0)\n httr         * 1.4.7      2023-08-15 [1] CRAN (R 4.4.0)\n jsonlite       1.8.9      2024-09-20 [1] CRAN (R 4.4.1)\n knitr          1.49       2024-11-08 [1] CRAN (R 4.4.1)\n labelled       2.13.0     2024-04-23 [1] CRAN (R 4.4.0)\n later          1.4.1      2024-11-27 [1] CRAN (R 4.4.1)\n lattice        0.22-6     2024-03-20 [1] CRAN (R 4.4.2)\n lifecycle      1.0.4      2023-11-07 [1] CRAN (R 4.4.0)\n lme4           1.1-35.5   2024-07-03 [1] CRAN (R 4.4.0)\n magrittr       2.0.3      2022-03-30 [1] CRAN (R 4.4.0)\n MASS           7.3-61     2024-06-13 [1] CRAN (R 4.4.2)\n mathjaxr       1.6-0      2022-02-28 [1] CRAN (R 4.4.0)\n Matrix       * 1.7-1      2024-10-18 [1] CRAN (R 4.4.2)\n memoise        2.0.1      2021-11-26 [1] CRAN (R 4.4.0)\n metadat      * 1.2-0      2022-04-06 [1] CRAN (R 4.4.0)\n metafor      * 4.6-0      2024-03-28 [1] CRAN (R 4.4.0)\n mime           0.12       2021-09-28 [1] CRAN (R 4.4.0)\n miniUI         0.1.1.1    2018-05-18 [1] CRAN (R 4.4.0)\n minqa          1.2.8      2024-08-17 [1] CRAN (R 4.4.0)\n nlme           3.1-166    2024-08-14 [1] CRAN (R 4.4.2)\n nloptr         2.1.1      2024-06-25 [1] CRAN (R 4.4.0)\n numDeriv     * 2016.8-1.1 2019-06-06 [1] CRAN (R 4.4.0)\n opalr        * 3.4.2      2024-09-18 [1] CRAN (R 4.4.1)\n pillar         1.10.1     2025-01-07 [1] CRAN (R 4.4.1)\n pkgbuild       1.4.5      2024-10-28 [1] CRAN (R 4.4.1)\n pkgconfig      2.0.3      2019-09-22 [1] CRAN (R 4.4.0)\n pkgload        1.4.0      2024-06-28 [1] CRAN (R 4.4.0)\n prettyunits    1.2.0      2023-09-24 [1] CRAN (R 4.4.0)\n profvis        0.4.0      2024-09-20 [1] CRAN (R 4.4.1)\n progress     * 1.2.3      2023-12-06 [1] CRAN (R 4.4.0)\n promises       1.3.2      2024-11-28 [1] CRAN (R 4.4.1)\n purrr          1.0.2      2023-08-10 [1] CRAN (R 4.4.0)\n R6           * 2.5.1      2021-08-19 [1] CRAN (R 4.4.0)\n Rcpp           1.0.13-1   2024-11-02 [1] CRAN (R 4.4.1)\n readr          2.1.5      2024-01-10 [1] CRAN (R 4.4.0)\n remotes        2.5.0      2024-03-17 [1] CRAN (R 4.4.0)\n rlang          1.1.4      2024-06-04 [1] CRAN (R 4.4.0)\n rmarkdown      2.29       2024-11-04 [1] CRAN (R 4.4.1)\n sessioninfo    1.2.2      2021-12-06 [1] CRAN (R 4.4.0)\n shiny          1.10.0     2024-12-14 [1] CRAN (R 4.4.1)\n stringi        1.8.4      2024-05-06 [1] CRAN (R 4.4.0)\n stringr        1.5.1      2023-11-14 [1] CRAN (R 4.4.0)\n tibble         3.2.1      2023-03-20 [1] CRAN (R 4.4.0)\n tidyr          1.3.1      2024-01-24 [1] CRAN (R 4.4.0)\n tidyselect     1.2.1      2024-03-11 [1] CRAN (R 4.4.0)\n tzdb           0.4.0      2023-05-12 [1] CRAN (R 4.4.0)\n urlchecker     1.0.1      2021-11-30 [1] CRAN (R 4.4.0)\n usethis        3.1.0      2024-11-26 [1] CRAN (R 4.4.1)\n vctrs          0.6.5      2023-12-01 [1] CRAN (R 4.4.0)\n xfun           0.49       2024-10-31 [1] CRAN (R 4.4.1)\n xtable         1.8-4      2019-04-21 [1] CRAN (R 4.4.0)\n yaml           2.3.10     2024-07-26 [1] CRAN (R 4.4.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#logging-in-and-assigning-data",
    "href": "chapters/datashield.html#logging-in-and-assigning-data",
    "title": "DataSHIELD Workshop",
    "section": "Logging in and assigning data",
    "text": "Logging in and assigning data\nThe login script has to be customized to fit the data you are trying to connect to.\nThe “builder &lt;-” and “builder$append” functions are standard features.\nFor this demonstration we are connecting to simulated data- but if it was data of real people, it would be very important for us not to be able to see individual patients’ information.\nLet’s log in to the  to see what data is available.\nWe will use the simulated dataset CNSIM, in a data.frame with 4128 observations of 11 harmonized variables. The CNSIM dataset contains synthetic data based on a model derived from the participants of the 1958 Birth Cohort, as part of the obesity methodological development project. This dataset does contain some NA values.\nFor the ease of this workshop, we’ll imagine that each study is hosted by a different partner of DataSHIELD: the first by UMCG Groningen (where EUCAN-Connect is based), the second by Liverpool University (where DataSHIELD core team is based) and the third by Barcelona (where ISGlobal is based). The below code creates a local R object with the login details for each study:\n\nbuilder &lt;- DSI::newDSLoginBuilder()\nbuilder$append(server = \"study1\", url = \"https://opal-demo.obiba.org\", user = \"dsuser\", password = \"P@ssw0rd\", table = \"CNSIM.CNSIM1\", driver = \"OpalDriver\", options='list(ssl_verifyhost=0, ssl_verifypeer=0)')\nbuilder$append(server = \"study2\", url = \"https://opal-demo.obiba.org\", user = \"dsuser\", password = \"P@ssw0rd\", table = \"CNSIM.CNSIM2\", driver = \"OpalDriver\", options='list(ssl_verifyhost=0, ssl_verifypeer=0)')\nbuilder$append(server = \"study3\", url = \"https://opal-demo.obiba.org\", user = \"dsuser\", password = \"P@ssw0rd\", table = \"CNSIM.CNSIM3\", driver = \"OpalDriver\", options='list(ssl_verifyhost=0, ssl_verifypeer=0)')\nlogindata &lt;- builder$build()\n\nThe error message displayed here- in production, would use https. But no need here (a self-contained environment, no risks).\nNow we need to connect, referring to the login information in the data frame we have just created:\n\nconnections &lt;- DSI::datashield.login(logins = logindata, assign = TRUE, symbol = \"D\")\n\n\nLogging into the collaborating servers\n\n\n\n  No variables have been specified. \n  All the variables in the table \n  (the whole dataset) will be assigned to R!\n\n\n\nAssigning table data...\n\n\nThe ‘assign’ argument can be set to either ‘TRUE’ or ‘FALSE’. If set to ‘TRUE’, all the available variables within that table will be assigned to a serverside data frame and available to access. If you only need a small subset of available variables it can be preferable to set this to ‘FALSE’ and later use the function ‘datashield.assign’ to separately assign only the variables you need. The output of this box has useful progress bars which show the progress of connecting to studies, one by one.\nWe can see the serverside object that has been created by running:\n\nds.ls()\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n[1] \"D\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n[1] \"D\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n[1] \"D\"\n\n\nHere you see one dataframe in each study called ‘D’ (this name was set using the ‘symbol’ argument in datashield.login above).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#describing-data-aggregate-type-functions",
    "href": "chapters/datashield.html#describing-data-aggregate-type-functions",
    "title": "DataSHIELD Workshop",
    "section": "Describing data (‘aggregate-type functions’)",
    "text": "Describing data (‘aggregate-type functions’)\nFirst use the Opal web portal to explore the metadata of ega_phenotypes.\nGo to the url: https://opal-demo.obiba.org/ui/index.html#!project;name=CNSIM;tab=TABLES\nAnd log in using the basic analyst’s user-password combination: user / password (your browser may warn you about insecurity but again, this is not important as it is only on the local network).\nHere you will be able to check on the metadata of what you are studying, to get ideas about what commands you may want to run on which variable.\nThere are many data exploration functions already implemented into DataSHIELD: let’s check it out at the wiki https://data2knowledge.atlassian.net/wiki/spaces/DSDEV/pages/1184825438/List+of+all+DataSHIELD+functions+v6.1\nScroll down to “Data structure queries”. Let’s try out a few of these:\n\nds.dim(x=\"D\", datasources= connections)\n\n$`dimensions of D in study1`\n[1] 2163   11\n\n$`dimensions of D in study2`\n[1] 3088   11\n\n$`dimensions of D in study3`\n[1] 4128   11\n\n$`dimensions of D in combined studies`\n[1] 9379   11\n\nds.colnames(x=\"D\", datasources= connections)\n\n$study1\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\"\n\n$study2\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\"\n\n$study3\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\"\n\n\n\nWe’re going to be focus on hdl_cholesterol.\nThis is a measure of HDL Cholesterol (aka the “good cholesterol” level)\nLet’s run some summary statistic commands\n\nds.class(x='D$LAB_HDL', datasources = connections)\n\n$study1\n[1] \"numeric\"\n\n$study2\n[1] \"numeric\"\n\n$study3\n[1] \"numeric\"\n\nds.length(x='D$LAB_HDL', datasources = connections)\n\n$`length of D$LAB_HDL in study1`\n[1] 2163\n\n$`length of D$LAB_HDL in study2`\n[1] 3088\n\n$`length of D$LAB_HDL in study3`\n[1] 4128\n\n$`total length of D$LAB_HDL in all studies combined`\n[1] 9379\n\nds.mean(x='D$LAB_HDL', datasources = connections)\n\n$Mean.by.Study\n       EstimatedMean Nmissing Nvalid Ntotal\nstudy1      1.569416      360   1803   2163\nstudy2      1.556648      555   2533   3088\nstudy3      1.574687      655   3473   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\n\nWhat is this other function to obtain the mean? Let’s use the DataSHIELD function help documentation.\n\n?ds.quantileMean\n\nNow, putting into action some of what we’ve learned about the function arguments.\n\nds.quantileMean(x='D$LAB_HDL', datasources = connections)\n\n Quantiles of the pooled data\n\n\n       5%       10%       25%       50%       75%       90%       95%      Mean \n0.8678198 1.0388227 1.2998328 1.5787193 1.8481549 2.0896969 2.2302836 1.5676188 \n\nds.quantileMean(x='D$LAB_HDL',type = \"split\", datasources = connections)\n\n$study1\n      5%      10%      25%      50%      75%      90%      95%     Mean \n0.875240 1.047400 1.300000 1.581000 1.844500 2.090000 2.210900 1.569416 \n\n$study2\n      5%      10%      25%      50%      75%      90%      95%     Mean \n0.850280 1.032200 1.294000 1.563000 1.840000 2.077000 2.225000 1.556648 \n\n$study3\n      5%      10%      25%      50%      75%      90%      95%     Mean \n0.876760 1.039200 1.304000 1.589000 1.856000 2.098800 2.244200 1.574687 \n\n\nTrying to calculate the variance of HDL Cholesterol:\n\n?ds.var\n\n\nds.var(x = \"D$LAB_HDL\", type = \"split\", datasources = connections)\n\n$Variance.by.Study\n       EstimatedVar Nmissing Nvalid Ntotal\nstudy1    0.1707959      360   1803   2163\nstudy2    0.1786661      555   2533   3088\nstudy3    0.1785256      655   3473   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\n\nCan we store the results calculated from a DataSHIELD analysis in a local R session?\nYes- the output of aggregate functions are always R objects, hence can be stored.\n\na&lt;-ds.var(x = \"D$LAB_HDL\", type = \"split\", datasources = connections)[[1]]\na\n\n       EstimatedVar Nmissing Nvalid Ntotal\nstudy1    0.1707959      360   1803   2163\nstudy2    0.1786661      555   2533   3088\nstudy3    0.1785256      655   3473   4128\n\nb&lt;-ds.var(x = \"D$LAB_HDL\", type = \"split\", datasources = connections)[[1]][[1,1]]\nb\n\n[1] 0.1707959\n\n\nThe square brackets are because we are trying to access an element of a list- which is the R object that DataSHIELD aggregate functions output as.\n\n\nUsing dsHelper to retrieve statistics in a neater format.\nAs you may have noticed, some operations which are more straightforward in R can be more complicated in datashield. To help with this, the dsHelper package allows you to do some common operations in fewer lines of code. DsHelper is an entirely serverside package - it contains only clientside functions which call DataSHIELD functions serverside.\nWe have seen datashield has a range of functions to retrieve statistics, but is limited in that (i) you need to use different functions for different statistics, (ii) you can only get stats for one variable at a time. dh.GetStats returns many useful stats in a tibble, and allows you to retrieve stats for multiple variables at a time.\n\nneat_stats &lt;- dh.getStats(\n    df = \"D\",\n  vars = c(\"LAB_TSC\", \"LAB_TRIG\", \"LAB_HDL\", \"LAB_GLUC_ADJUSTED\", \n           \"PM_BMI_CONTINUOUS\", \"DIS_CVA\", \"MEDI_LPD\", \"DIS_DIAB\", \"DIS_AMI\", \n           \"GENDER\", \"PM_BMI_CATEGORICAL\"))\n\nWarning: Automatic coercion from integer to character was deprecated in purrr 1.0.0.\nℹ Please use an explicit call to `as.character()` within `map_chr()` instead.\nℹ The deprecated feature was likely used in the base package.\n  Please report the issue to the authors.\n\nneat_stats\n\n$categorical\n# A tibble: 64 × 10\n   variable cohort   category value cohort_n valid_n missing_n perc_valid\n   &lt;chr&gt;    &lt;chr&gt;    &lt;fct&gt;    &lt;int&gt;    &lt;int&gt;   &lt;int&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1 DIS_CVA  combined 0         9365     9379    9379         0      99.8 \n 2 DIS_CVA  combined 1           14     9379    9379         0       0.15\n 3 DIS_CVA  combined &lt;NA&gt;         0     9379      NA        NA      NA   \n 4 DIS_DIAB combined 0         9233     9379    9379         0      98.4 \n 5 DIS_DIAB combined 1          146     9379    9379         0       1.56\n 6 DIS_DIAB combined &lt;NA&gt;         0     9379      NA        NA      NA   \n 7 GENDER   combined 0         4768     9379    9379         0      50.8 \n 8 GENDER   combined 1         4611     9379    9379         0      49.2 \n 9 GENDER   combined &lt;NA&gt;         0     9379      NA        NA      NA   \n10 MEDI_LPD combined 0         9203     9379    9379         0      98.1 \n# ℹ 54 more rows\n# ℹ 2 more variables: perc_missing &lt;dbl&gt;, perc_total &lt;dbl&gt;\n\n$continuous\n# A tibble: 20 × 15\n   variable  cohort  mean std.dev perc_5 perc_10 perc_25 perc_50 perc_75 perc_90\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 LAB_GLUC… study1  6.12    1.38   4.09    4.53    5.24    6.07    6.87    7.67\n 2 LAB_GLUC… study2  6.1     1.37   4.1     4.55    5.21    6.03    6.85    7.62\n 3 LAB_GLUC… study3  6.11    1.35   4.11    4.53    5.21    6.06    6.86    7.62\n 4 LAB_HDL   study1  1.57    0.41   0.88    1.05    1.3     1.58    1.84    2.09\n 5 LAB_HDL   study2  1.56    0.42   0.85    1.03    1.29    1.56    1.84    2.08\n 6 LAB_HDL   study3  1.57    0.42   0.88    1.04    1.3     1.59    1.86    2.1 \n 7 LAB_TRIG  study1  2.1     1.58  -0.36    0.17    1.04    2.11    3.12    4.07\n 8 LAB_TRIG  study2  2.05    1.58  -0.55    0.01    1       2.05    3.06    4.03\n 9 LAB_TRIG  study3  2.02    1.54  -0.51    0.14    1.01    2.02    3.04    3.97\n10 LAB_TSC   study1  5.87    1.11   4.09    4.49    5.11    5.86    6.59    7.31\n11 LAB_TSC   study2  5.85    1.07   4.14    4.51    5.15    5.82    6.51    7.18\n12 LAB_TSC   study3  5.85    1.07   4.2     4.58    5.11    5.79    6.51    7.26\n13 PM_BMI_C… study1 27.4     5.02  19.5    21.1    24.1    27.3    30.7    33.8 \n14 PM_BMI_C… study2 27.5     4.9   19.4    21.3    24.2    27.4    30.7    33.8 \n15 PM_BMI_C… study3 27.4     4.82  19.5    21.4    24.2    27.4    30.7    33.5 \n16 LAB_GLUC… combi…  6.11    1.37   4.1     4.54    5.22    6.05    6.86    7.63\n17 LAB_HDL   combi…  1.57    0.42   0.87    1.04    1.3     1.58    1.85    2.09\n18 LAB_TRIG  combi…  2.05    1.56  -0.49    0.1     1.01    2.05    3.06    4.01\n19 LAB_TSC   combi…  5.85    1.08   4.15    4.54    5.12    5.81    6.53    7.24\n20 PM_BMI_C… combi… 27.4     4.9   19.5    21.3    24.2    27.4    30.7    33.6 \n# ℹ 5 more variables: perc_95 &lt;dbl&gt;, valid_n &lt;dbl&gt;, cohort_n &lt;dbl&gt;,\n#   missing_n &lt;dbl&gt;, missing_perc &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#manipulating-data-assign-type-functions",
    "href": "chapters/datashield.html#manipulating-data-assign-type-functions",
    "title": "DataSHIELD Workshop",
    "section": "Manipulating data (‘assign-type’ functions)",
    "text": "Manipulating data (‘assign-type’ functions)\nAssign-type functions are ones where a calculation is done on the data stored at the server (and results of that calculation are “assigned” to a serverside variable, and saved there), but is NOT transmitted back to the user.\nThe reason for this is that some calculations could be highly disclosive- and if such data were transmitted to the analyst, with not much effort at all, with an inverse function, the analyst could work out exactly what the raw data are- and thus the data’s privacy is broken!\nTo demonstrate:\n\nds.ls(datasources = connections)\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n[1] \"D\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n[1] \"D\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n[1] \"D\"\n\nds.log(x='D$LAB_HDL', newobj='LAB_HDL_log', datasources = connections)\nds.ls(datasources = connections)\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n[1] \"D\"           \"LAB_HDL_log\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n[1] \"D\"           \"LAB_HDL_log\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n[1] \"D\"           \"LAB_HDL_log\"\n\nds.mean(x=\"LAB_HDL_log\",datasources= connections)\n\n$Mean.by.Study\n       EstimatedMean Nmissing Nvalid Ntotal\nstudy1     0.4086112      361   1802   2163\nstudy2     0.3971793      558   2530   3088\nstudy3     0.4134147      662   3466   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\nds.mean(x=\"D$LAB_HDL\",datasources= connections)\n\n$Mean.by.Study\n       EstimatedMean Nmissing Nvalid Ntotal\nstudy1      1.569416      360   1803   2163\nstudy2      1.556648      555   2533   3088\nstudy3      1.574687      655   3473   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\n\nThe second “ds.mean” shows that the mean of the logged values are definitely smaller, by about the right amount. The DataSHIELD log function has worked.\nThere is another DataSHIELD assign function that can be used for data transformations - a square root function. Let’s test again:\n\nds.sqrt(x='D$LAB_HDL', newobj='LAB_HDL_sqrt', datasources = connections)\nds.ls(datasources = connections)\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n[1] \"D\"            \"LAB_HDL_log\"  \"LAB_HDL_sqrt\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n[1] \"D\"            \"LAB_HDL_log\"  \"LAB_HDL_sqrt\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n[1] \"D\"            \"LAB_HDL_log\"  \"LAB_HDL_sqrt\"\n\nds.mean(x=\"LAB_HDL_sqrt\",datasources= connections)\n\n$Mean.by.Study\n       EstimatedMean Nmissing Nvalid Ntotal\nstudy1      1.240844      361   1802   2163\nstudy2      1.235489      558   2530   3088\nstudy3      1.243899      662   3466   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\nds.mean(x=\"D$LAB_HDL\",datasources= connections)\n\n$Mean.by.Study\n       EstimatedMean Nmissing Nvalid Ntotal\nstudy1      1.569416      360   1803   2163\nstudy2      1.556648      555   2533   3088\nstudy3      1.574687      655   3473   4128\n\n$Nstudies\n[1] 3\n\n$ValidityMessage\n       ValidityMessage \nstudy1 \"VALID ANALYSIS\"\nstudy2 \"VALID ANALYSIS\"\nstudy3 \"VALID ANALYSIS\"\n\n\nThese new objects are not attached to a dataframe. Use the help function to find out about the ds.dataFrame function, which can be used to combine objects.\nNow join “LAB_HDL_sqrt” and “LAB_HDL_log” to the dataframe “D”.\n\nds.dataFrame(c(\"D\", \"LAB_HDL_sqrt\", \"LAB_HDL_log\"), newobj = \"D\")\n\n$is.object.created\n[1] \"A data object &lt;D&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D&gt; appears valid in all sources\"\n\nds.colnames(\"D\")\n\n$study1\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n$study2\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n$study3\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n\nUsing some of the functions above, explore the distribution of the variable “PM_BMI_CATEGORICAL” in dataframe “D”.\nHere you see this has returned a list of two tibbles separated into continuous and categorical information. For the categorical variables info is returned on ns, percentages and missingness within each category, whilst for continuous variables info is returned on mean, standard deviation, quantiles and also missingness.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#sub-setting-data",
    "href": "chapters/datashield.html#sub-setting-data",
    "title": "DataSHIELD Workshop",
    "section": "Sub-setting data",
    "text": "Sub-setting data\nIn DataSHIELD there is one function that allows sub-setting of data, ds.dataFrameSubset .\nYou may wish to use it to:\nSubset a column of data by its “Class” Subset a dataframe to remove any “NA”s Subset a numeric column of a dataframe using a Boolean inequalilty\n\n# first find the column name you wish to refer to\nds.colnames(x=\"D\")\n\n$study1\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n$study2\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n$study3\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"PM_BMI_CONTINUOUS\"  \"DIS_CVA\"           \n [7] \"MEDI_LPD\"           \"DIS_DIAB\"           \"DIS_AMI\"           \n[10] \"GENDER\"             \"PM_BMI_CATEGORICAL\" \"LAB_HDL_sqrt\"      \n[13] \"LAB_HDL_log\"       \n\n# then check which levels you need to apply a boolean operator to:\nds.levels(x=\"D$GENDER\")\n\n$study1\n$study1$Levels\n[1] \"0\" \"1\"\n\n$study1$ValidityMessage\n[1] \"VALID ANALYSIS\"\n\n\n$study2\n$study2$Levels\n[1] \"0\" \"1\"\n\n$study2$ValidityMessage\n[1] \"VALID ANALYSIS\"\n\n\n$study3\n$study3$Levels\n[1] \"0\" \"1\"\n\n$study3$ValidityMessage\n[1] \"VALID ANALYSIS\"\n\n?ds.dataFrameSubset\n\nSplitting into GENDER groups, assigned to different server-side objects.\n\nds.dataFrameSubset(df.name = \"D\", V1.name = \"D$GENDER\", V2.name = \"1\", Boolean.operator = \"==\", newobj = \"CNSIM.subset.Males\", datasources= connections)\n\n$is.object.created\n[1] \"A data object &lt;CNSIM.subset.Males&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;CNSIM.subset.Males&gt; appears valid in all sources\"\n\nds.dataFrameSubset(df.name = \"D\", V1.name = \"D$GENDER\", V2.name = \"0\", Boolean.operator = \"==\", newobj = \"CNSIM.subset.Females\",datasources= connections)\n\n$is.object.created\n[1] \"A data object &lt;CNSIM.subset.Females&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;CNSIM.subset.Females&gt; appears valid in all sources\"\n\n\nNow there are two serverside objects which have split GENDER by class, to which we have assigned the names “CNSIM.subset.Males” and “CNSIM.subset.Females”.\n\nSub-setting to remove NAs\n\nds.completeCases(x1=\"D\",newobj=\"D_without_NA\", datasources=connections)\n\n$is.object.created\n[1] \"A data object &lt;D_without_NA&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D_without_NA&gt; appears valid in all sources\"\n\n\n\n\nSub-setting by inequality\nSay we wanted to have a subset of patients where BMI values are ≥ 25, and call it subset.BMI.25.plus\n\nds.dataFrameSubset(df.name = \"D\",\n  V1.name = \"D$PM_BMI_CONTINUOUS\",\n  V2.name = \"25\",\n  Boolean.operator = \"&gt;=\",\n  newobj = \"subset.BMI.25.plus\",\n  datasources = connections)\n\n$is.object.created\n[1] \"A data object &lt;subset.BMI.25.plus&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;subset.BMI.25.plus&gt; appears valid in all sources\"\n\n\nChecking we have successfully created such an object, using quantiles and histograms:\n\nds.quantileMean(x=\"subset.BMI.25.plus$PM_BMI_CONTINUOUS\", type = \"split\", datasources= connections)\n\n$study1\n     5%     10%     25%     50%     75%     90%     95%    Mean \n25.3500 25.7100 27.1500 29.2000 32.0600 34.6560 36.4980 29.9019 \n\n$study2\n      5%      10%      25%      50%      75%      90%      95%     Mean \n25.46900 25.91800 27.19000 29.27000 32.20500 34.76200 36.24300 29.92606 \n\n$study3\n      5%      10%      25%      50%      75%      90%      95%     Mean \n25.43000 25.96000 27.17000 29.32000 31.94000 34.35200 36.08100 29.86534 \n\nds.histogram(x=\"subset.BMI.25.plus$PM_BMI_CONTINUOUS\", datasources = connections)\n\nWarning: study1: 2 invalid cells\n\n\nWarning: study2: 1 invalid cells\n\n\nWarning: study3: 0 invalid cells\n\n\n[[1]]\n$breaks\n [1] 24.53224 27.68450 30.83675 33.98901 37.14126 40.29352 43.44578 46.59803\n [9] 49.75029 52.90254 56.05480\n\n$counts\n [1] 455 481 294 135  42  14   0   0   0   0\n\n$density\n [1] 0.101291997 0.107080111 0.065450213 0.030053669 0.009350030 0.003116677\n [7] 0.000000000 0.000000000 0.000000000 0.000000000\n\n$mids\n [1] 26.10837 29.26063 32.41288 35.56514 38.71739 41.86965 45.02190 48.17416\n [9] 51.32641 54.47867\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[2]]\n$breaks\n [1] 24.53224 27.68450 30.83675 33.98901 37.14126 40.29352 43.44578 46.59803\n [9] 49.75029 52.90254 56.05480\n\n$counts\n [1] 639 691 435 202  58  10   3   0   0   0\n\n$density\n [1] 0.0994173616 0.1075076633 0.0676784856 0.0314277106 0.0090237981\n [6] 0.0015558273 0.0004667482 0.0000000000 0.0000000000 0.0000000000\n\n$mids\n [1] 26.10837 29.26063 32.41288 35.56514 38.71739 41.86965 45.02190 48.17416\n [9] 51.32641 54.47867\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[3]]\n$breaks\n [1] 24.53224 27.68450 30.83675 33.98901 37.14126 40.29352 43.44578 46.59803\n [9] 49.75029 52.90254 56.05480\n\n$counts\n [1] 840 922 636 222  68  18   4   0   0   0\n\n$density\n [1] 0.0983305789 0.1079295164 0.0744502955 0.0259873673 0.0079600945\n [6] 0.0021070838 0.0004682409 0.0000000000 0.0000000000 0.0000000000\n\n$mids\n [1] 26.10837 29.26063 32.41288 35.56514 38.71739 41.86965 45.02190 48.17416\n [9] 51.32641 54.47867\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\n\n\n\n\n\n\n\n\n\nSub-setting by multiple conditions\nIf we want to create a subset based on multiple conditions we can use the ds.Boole function before subsetting. For example, let’s say that we want to create a subset of individuals where BMI values are ≥ 25 and adjusted glucose is lower than 6.\n\nds.Boole(\n  V1 = \"D$PM_BMI_CONTINUOUS\",\n  V2 = \"25\",\n  Boolean.operator = \"&gt;=\",\n  numeric.output = TRUE,\n  newobj = \"BMI.25.plus\",\n  datasources = connections)\n\n$is.object.created\n[1] \"A data object &lt;BMI.25.plus&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;BMI.25.plus&gt; appears valid in all sources\"\n\nds.Boole(\n  V1 = \"D$LAB_GLUC_ADJUSTED\",\n  V2 = \"6\",\n  Boolean.operator = \"&lt;\",\n  numeric.output = TRUE,\n  newobj = \"GLUC.6.less\",\n  datasources = connections)\n\n$is.object.created\n[1] \"A data object &lt;GLUC.6.less&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;GLUC.6.less&gt; appears valid in all sources\"\n\n\nWe can then use the ds.make function to make a new categorical variable which combines these groups:\n\n?ds.make \n\nds.make(toAssign = \"BMI.25.plus+GLUC.6.less\",\n        newobj = \"BMI.25.plus_GLUC.6.less\",\n        datasources = connections)\n\n$is.object.created\n[1] \"A data object &lt;BMI.25.plus_GLUC.6.less&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;BMI.25.plus_GLUC.6.less&gt; appears valid in all sources\"\n\n# If BMI &gt;= 25 and glucose &lt; 6, then BMI.25.plus_GLUC.6.less=2\n# If BMI &gt;= 25 and glucose &gt;= 6, then BMI.25.plus_GLUC.6.less=1\n# If BMI &lt; 25 and glucose &lt; 6, then BMI.25.plus_GLUC.6.less=1\n# If BMI &lt; 25 and glucose &gt;= 6, then BMI.25.plus_GLUC.6.less=0\n\nds.table(rvar= \"BMI.25.plus_GLUC.6.less\",\n         datasources = connections)\n\n\n Data in all studies were valid \n\nStudy 1 :  No errors reported from this study\nStudy 2 :  No errors reported from this study\nStudy 3 :  No errors reported from this study\n\n\n$output.list\n$output.list$TABLE_rvar.by.study_row.props\n                       study\nBMI.25.plus_GLUC.6.less    study1    study2    study3\n                     0  0.2400000 0.3293023 0.4306977\n                     1  0.2299020 0.3171569 0.4529412\n                     2  0.2259655 0.3422350 0.4317995\n                     NA 0.2329609 0.3391061 0.4279330\n\n$output.list$TABLE_rvar.by.study_col.props\n                       study\nBMI.25.plus_GLUC.6.less    study1    study2    study3\n                     0  0.1192788 0.1146373 0.1121609\n                     1  0.4336570 0.4190415 0.4476744\n                     2  0.2542765 0.2697539 0.2546027\n                     NA 0.1927878 0.1965674 0.1855620\n\n$output.list$TABLE_rvar.by.study_counts\n                       study\nBMI.25.plus_GLUC.6.less study1 study2 study3\n                     0     258    354    463\n                     1     938   1294   1848\n                     2     550    833   1051\n                     NA    417    607    766\n\n$output.list$TABLES.COMBINED_all.sources_proportions\nBMI.25.plus_GLUC.6.less\n    0     1     2    NA \n0.115 0.435 0.260 0.191 \n\n$output.list$TABLES.COMBINED_all.sources_counts\nBMI.25.plus_GLUC.6.less\n   0    1    2   NA \n1075 4080 2434 1790 \n\n\n$validity.message\n[1] \"Data in all studies were valid\"\n\nds.dataFrame(x=c(\"D\", \"BMI.25.plus_GLUC.6.less\"), newobj = \"D2\")\n\n$is.object.created\n[1] \"A data object &lt;D2&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;D2&gt; appears valid in all sources\"\n\nds.colnames(\"D2\")\n\n$study1\n [1] \"LAB_TSC\"                 \"LAB_TRIG\"               \n [3] \"LAB_HDL\"                 \"LAB_GLUC_ADJUSTED\"      \n [5] \"PM_BMI_CONTINUOUS\"       \"DIS_CVA\"                \n [7] \"MEDI_LPD\"                \"DIS_DIAB\"               \n [9] \"DIS_AMI\"                 \"GENDER\"                 \n[11] \"PM_BMI_CATEGORICAL\"      \"LAB_HDL_sqrt\"           \n[13] \"LAB_HDL_log\"             \"BMI.25.plus_GLUC.6.less\"\n\n$study2\n [1] \"LAB_TSC\"                 \"LAB_TRIG\"               \n [3] \"LAB_HDL\"                 \"LAB_GLUC_ADJUSTED\"      \n [5] \"PM_BMI_CONTINUOUS\"       \"DIS_CVA\"                \n [7] \"MEDI_LPD\"                \"DIS_DIAB\"               \n [9] \"DIS_AMI\"                 \"GENDER\"                 \n[11] \"PM_BMI_CATEGORICAL\"      \"LAB_HDL_sqrt\"           \n[13] \"LAB_HDL_log\"             \"BMI.25.plus_GLUC.6.less\"\n\n$study3\n [1] \"LAB_TSC\"                 \"LAB_TRIG\"               \n [3] \"LAB_HDL\"                 \"LAB_GLUC_ADJUSTED\"      \n [5] \"PM_BMI_CONTINUOUS\"       \"DIS_CVA\"                \n [7] \"MEDI_LPD\"                \"DIS_DIAB\"               \n [9] \"DIS_AMI\"                 \"GENDER\"                 \n[11] \"PM_BMI_CATEGORICAL\"      \"LAB_HDL_sqrt\"           \n[13] \"LAB_HDL_log\"             \"BMI.25.plus_GLUC.6.less\"\n\nds.dataFrameSubset(df.name = \"D2\",\n  V1.name = \"D2$BMI.25.plus_GLUC.6.less\",\n  V2.name = \"2\",\n  Boolean.operator = \"==\",\n  newobj = \"subset2\",\n  datasources = connections)\n\n$is.object.created\n[1] \"A data object &lt;subset2&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;subset2&gt; appears valid in all sources\"\n\nds.dim(\"subset2\")\n\n$`dimensions of subset2 in study1`\n[1] 550  14\n\n$`dimensions of subset2 in study2`\n[1] 833  14\n\n$`dimensions of subset2 in study3`\n[1] 1051   14\n\n$`dimensions of subset2 in combined studies`\n[1] 2434   14",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#data-manipulation-with-dshelper",
    "href": "chapters/datashield.html#data-manipulation-with-dshelper",
    "title": "DataSHIELD Workshop",
    "section": "Data manipulation with dsHelper",
    "text": "Data manipulation with dsHelper\nAgain, we can use some dsHelper functions to do data manipulation operations in a more efficient way.\n\nCreate a subset of columns by a vector of column names\n\ndh.dropCols(\n    df = \"D\", \n  vars = c(\"PM_BMI_CONTINUOUS\", \"GENDER\"), \n  type = \"keep\",\n  new_obj = \"df_subset\")\n\n$study1\n$study1$is.object.created\n[1] \"A data object &lt;df_subset&gt; has been created in all specified data sources\"\n\n$study1$validity.check\n[1] \"&lt;df_subset&gt; appears valid in all sources\"\n\n\n$study2\n$study2$is.object.created\n[1] \"A data object &lt;df_subset&gt; has been created in all specified data sources\"\n\n$study2$validity.check\n[1] \"&lt;df_subset&gt; appears valid in all sources\"\n\n\n$study3\n$study3$is.object.created\n[1] \"A data object &lt;df_subset&gt; has been created in all specified data sources\"\n\n$study3$validity.check\n[1] \"&lt;df_subset&gt; appears valid in all sources\"\n\nds.colnames(\"df_subset\")\n\n$study1\n[1] \"PM_BMI_CONTINUOUS\" \"GENDER\"           \n\n$study2\n[1] \"PM_BMI_CONTINUOUS\" \"GENDER\"           \n\n$study3\n[1] \"PM_BMI_CONTINUOUS\" \"GENDER\"           \n\n\n\n\nRename variables\n(Since we are doing this for demonstration purposes, we will keep the changes in a separate dataframe, so we will first create a copy of our original dataframe \"D\" with ds.assign)\n\nds.assign(toAssign = \"D\", newobj = \"df_rename\")\n\n# Then, we rename its variables\ndh.renameVars(\n    df = \"df_rename\", \n  current_names = c(\"PM_BMI_CONTINUOUS\", \"GENDER\"),\n  new_names = c(\"BMI\", \"SEX\"))\n  \nds.colnames(\"df_rename\")\n\n$study1\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"DIS_CVA\"            \"MEDI_LPD\"          \n [7] \"DIS_DIAB\"           \"DIS_AMI\"            \"PM_BMI_CATEGORICAL\"\n[10] \"LAB_HDL_sqrt\"       \"LAB_HDL_log\"        \"BMI\"               \n[13] \"SEX\"               \n\n$study2\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"DIS_CVA\"            \"MEDI_LPD\"          \n [7] \"DIS_DIAB\"           \"DIS_AMI\"            \"PM_BMI_CATEGORICAL\"\n[10] \"LAB_HDL_sqrt\"       \"LAB_HDL_log\"        \"BMI\"               \n[13] \"SEX\"               \n\n$study3\n [1] \"LAB_TSC\"            \"LAB_TRIG\"           \"LAB_HDL\"           \n [4] \"LAB_GLUC_ADJUSTED\"  \"DIS_CVA\"            \"MEDI_LPD\"          \n [7] \"DIS_DIAB\"           \"DIS_AMI\"            \"PM_BMI_CATEGORICAL\"\n[10] \"LAB_HDL_sqrt\"       \"LAB_HDL_log\"        \"BMI\"               \n[13] \"SEX\"               \n\n\nThere are many more dsHelper functions designed to make common operations easier in datashield, check out the vignettes at: https://lifecycle-project.github.io/ds-helper/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#graphs",
    "href": "chapters/datashield.html#graphs",
    "title": "DataSHIELD Workshop",
    "section": "Graphs",
    "text": "Graphs\nVisualising the data we are studying is extremely important to get a sense of it. While it may seem disclosive at first glance, only such graphs that are definitively non-disclosive have been implemented within the DataSHIELD project.\n\nHistograms\nFirstly, histograms give a good sense of how one variable is distributed. But no individual points are disclosed because values are “binned” into groups of a similar magnitude, disguising what each one actually is. We protect privacy by removing bins with low counts (below specific threshold). If you have a symmetric distribution, you may find some things aren’t observed at the extreme ends.\nLet’s create a histogram of the variable we’ve been investigating for much of this study: HDL Cholesterol (“LAB_HDL”).\n\n?ds.histogram\nds.histogram(x='D$LAB_HDL', datasources = connections)\n\nWarning: study1: 1 invalid cells\n\n\nWarning: study2: 1 invalid cells\n\n\nWarning: study3: 1 invalid cells\n\n\n[[1]]\n$breaks\n [1] -0.5076287 -0.1440722  0.2194844  0.5830410  0.9465975  1.3101541\n [7]  1.6737106  2.0372672  2.4008238  2.7643803  3.1279369\n\n$counts\n [1]   0   4  26  93 337 594 528 192  27   0\n\n$density\n [1] 0.000000000 0.006102282 0.039664833 0.141878057 0.514117262 0.906188883\n [7] 0.805501229 0.292909538 0.041190404 0.000000000\n\n$mids\n [1] -0.32585046  0.03770611  0.40126267  0.76481923  1.12837579  1.49193236\n [7]  1.85548892  2.21904548  2.58260204  2.94615861\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[2]]\n$breaks\n [1] -0.5076287 -0.1440722  0.2194844  0.5830410  0.9465975  1.3101541\n [7]  1.6737106  2.0372672  2.4008238  2.7643803  3.1279369\n\n$counts\n [1]   0   8  29 134 504 845 707 253  48   4\n\n$density\n [1] 0.00000000 0.00868726 0.03149132 0.14551160 0.54729737 0.91759181\n [7] 0.76773658 0.27473459 0.05212356 0.00434363\n\n$mids\n [1] -0.32585046  0.03770611  0.40126267  0.76481923  1.12837579  1.49193236\n [7]  1.85548892  2.21904548  2.58260204  2.94615861\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[3]]\n$breaks\n [1] -0.5076287 -0.1440722  0.2194844  0.5830410  0.9465975  1.3101541\n [7]  1.6737106  2.0372672  2.4008238  2.7643803  3.1279369\n\n$counts\n [1]    3   11   46  167  657 1131 1004  395   57    0\n\n$density\n [1] 0.002375989 0.008711961 0.036431836 0.132263405 0.520341660 0.895747971\n [7] 0.795164424 0.312838593 0.045143797 0.000000000\n\n$mids\n [1] -0.32585046  0.03770611  0.40126267  0.76481923  1.12837579  1.49193236\n [7]  1.85548892  2.21904548  2.58260204  2.94615861\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\n\n\n\n\n\n\n\nUse the ds.histogram to explore the distribution of “D$PM_BMI_CONTINUOUS”\n\n\nScatterplots of two numerical variables\nWhen you generate a scatter plot, you can say that the data points that are displayed are not the actual values. The function gives you the choice on how to anonymise: either you anonymise the values by additional random noise; or you take the average of the k nearest neighbours. (for more details on how anonymisation methods are used for the generation of privacy-preserving visualisations you can have a look on the paper https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-020-00257-4)\n\nds.scatterPlot(x=\"D$LAB_HDL\", y=\"D$PM_BMI_CONTINUOUS\", datasources = connections)\n\n[1] \"Split plot created\"\n\n\n\n\n\n\n\n\n\nOther DataSHIELD graphical functions allow the creation of box plots, heatmap plots and contour plots. Investigate them using their help functions:\n\n?ds.heatmapPlot\n?ds.contourPlot\n?ds.boxPlot",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#analysis",
    "href": "chapters/datashield.html#analysis",
    "title": "DataSHIELD Workshop",
    "section": "Analysis",
    "text": "Analysis\n\nSimple Linear Regression\nWe want to examine the relationship between BMI and HDL Cholesterol\n\nds.cor(x='D$PM_BMI_CONTINUOUS', y='D$LAB_HDL')\n\n$study1\n$study1$`Number of missing values in each variable`\n     x.val y.val\n[1,]    97   360\n\n$study1$`Number of missing values casewise`\n      x.val y.val\nx.val   431   431\ny.val   431   431\n\n$study1$`Correlation Matrix`\n           [,1]       [,2]\n[1,]  1.0000000 -0.1245574\n[2,] -0.1245574  1.0000000\n\n$study1$`Number of complete cases used`\n      x.val y.val\nx.val  1732  1732\ny.val  1732  1732\n\n\n$study2\n$study2$`Number of missing values in each variable`\n     x.val y.val\n[1,]   150   555\n\n$study2$`Number of missing values casewise`\n      x.val y.val\nx.val   656   656\ny.val   656   656\n\n$study2$`Correlation Matrix`\n           [,1]       [,2]\n[1,]  1.0000000 -0.1408146\n[2,] -0.1408146  1.0000000\n\n$study2$`Number of complete cases used`\n      x.val y.val\nx.val  2432  2432\ny.val  2432  2432\n\n\n$study3\n$study3$`Number of missing values in each variable`\n     x.val y.val\n[1,]   205   655\n\n$study3$`Number of missing values casewise`\n      x.val y.val\nx.val   807   807\ny.val   807   807\n\n$study3$`Correlation Matrix`\n           [,1]       [,2]\n[1,]  1.0000000 -0.1453906\n[2,] -0.1453906  1.0000000\n\n$study3$`Number of complete cases used`\n      x.val y.val\nx.val  3321  3321\ny.val  3321  3321\n\n\nRegress HDL Cholesterol with BMI using the Individual Partition Data (IPD) approach:\nThe method for this (ds.glm) is a “pooled analysis”- equivalent to placing the individual-level data from all sources in one warehouse.\nImportant to note that the link function is by default the canonical link function for each family. So binomial &lt;-&gt; logistic link, poisson &lt;-&gt; log link, gaussian &lt;-&gt; identity link.\n\nds.glm(formula = \"D$LAB_HDL~D$PM_BMI_CONTINUOUS\", family=\"gaussian\", datasources = connections)\n\nIteration 1...\n\n\nCURRENT DEVIANCE:      19765.404445561\n\n\nIteration 2...\n\n\nCURRENT DEVIANCE:      1297.45709088487\n\n\nIteration 3...\n\n\nCURRENT DEVIANCE:      1297.45709088487\n\n\nSUMMARY OF MODEL STATE after iteration 3\n\n\nCurrent deviance 1297.45709088487 on 7483 degrees of freedom\n\n\nConvergence criterion TRUE (0)\n\n\n\nbeta: 1.90261171060757 -0.0121577380319686\n\n\n\nInformation matrix overall:\n\n\n                    (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)              7485.0            204970.6\nD$PM_BMI_CONTINUOUS    204970.6           5786443.7\n\n\n\nScore vector overall:\n\n\n                            [,1]\n(Intercept)         3.620215e-12\nD$PM_BMI_CONTINUOUS 8.333245e-11\n\n\n\nCurrent deviance: 1297.45709088487\n\n\n$Nvalid\n[1] 7485\n\n$Nmissing\n[1] 1894\n\n$Ntotal\n[1] 9379\n\n$disclosure.risk\n       RISK OF DISCLOSURE\nstudy1                  0\nstudy2                  0\nstudy3                  0\n\n$errorMessage\n       ERROR MESSAGES\nstudy1 \"No errors\"   \nstudy2 \"No errors\"   \nstudy3 \"No errors\"   \n\n$nsubs\n[1] 7485\n\n$iter\n[1] 3\n\n$family\n\nFamily: gaussian \nLink function: identity \n\n\n$formula\n[1] \"D$LAB_HDL ~ D$PM_BMI_CONTINUOUS\"\n\n$coefficients\n                       Estimate   Std. Error   z-value      p-value   low0.95CI\n(Intercept)          1.90261171 0.0277958082  68.44959 0.000000e+00  1.84813293\nD$PM_BMI_CONTINUOUS -0.01215774 0.0009996992 -12.16140 4.989844e-34 -0.01411711\n                     high0.95CI\n(Intercept)          1.95709049\nD$PM_BMI_CONTINUOUS -0.01019836\n\n$dev\n[1] 1297.457\n\n$df\n[1] 7483\n\n$output.information\n[1] \"SEE TOP OF OUTPUT FOR INFORMATION ON MISSING DATA AND ERROR MESSAGES\"\n\n\nRegress HDL Cholesterol with BMI using the Study-Level Meta-Analysis (SLMA) approach:\n\nds.glmSLMA(formula = \"D$LAB_HDL~D$PM_BMI_CONTINUOUS\", family=\"gaussian\", newobj = \"workshop.obj\", datasources = connections)\n\n$output.summary\n$output.summary$study1\n$output.summary$study1$rank\n[1] 2\n\n$output.summary$study1$aic\n[1] 1823.266\n\n$output.summary$study1$iter\n[1] 2\n\n$output.summary$study1$converged\n[1] TRUE\n\n$output.summary$study1$boundary\n[1] FALSE\n\n$output.summary$study1$na.action\n$output.summary$study1$na.action$na.action\n[1] \"na.omit\"\n\n\n$output.summary$study1$call\nglm(formula = formula, family = gaussian, x = TRUE)\n\n$output.summary$study1$terms\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\nattr(,\"variables\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"factors\")\n                    D$PM_BMI_CONTINUOUS\nD$LAB_HDL                             0\nD$PM_BMI_CONTINUOUS                   1\nattr(,\"term.labels\")\n[1] \"D$PM_BMI_CONTINUOUS\"\nattr(,\"order\")\n[1] 1\nattr(,\"intercept\")\n[1] 1\nattr(,\"response\")\n[1] 1\nattr(,\".Environment\")\n&lt;environment: R_GlobalEnv&gt;\nattr(,\"predvars\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"dataClasses\")\n          D$LAB_HDL D$PM_BMI_CONTINUOUS \n          \"numeric\"           \"numeric\" \n\n$output.summary$study1$contrasts\nNULL\n\n$output.summary$study1$aliased\n        (Intercept) D$PM_BMI_CONTINUOUS \n              FALSE               FALSE \n\n$output.summary$study1$dispersion\n[1] 0.1673794\n\n$output.summary$study1$data\nNULL\n\n$output.summary$study1$df\n[1]    2 1730    2\n\n$output.summary$study1$Ntotal\n[1] 2163\n\n$output.summary$study1$Nvalid\n[1] 1732\n\n$output.summary$study1$Nmissing\n[1] 431\n\n$output.summary$study1$cov.unscaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          0.0188122406       -6.660371e-04\nD$PM_BMI_CONTINUOUS -0.0006660371        2.432731e-05\n\n$output.summary$study1$cov.scaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          0.0031487822       -1.114809e-04\nD$PM_BMI_CONTINUOUS -0.0001114809        4.071892e-06\n\n$output.summary$study1$offset\nNULL\n\n$output.summary$study1$weights\nNULL\n\n$output.summary$study1$VarCovMatrix\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          0.0031487822       -1.114809e-04\nD$PM_BMI_CONTINUOUS -0.0001114809        4.071892e-06\n\n$output.summary$study1$CorrMatrix\n           [,1]       [,2]\n[1,]  1.0000000 -0.9845349\n[2,] -0.9845349  1.0000000\n\n$output.summary$study1$deviance.null\n[1] 294.1297\n\n$output.summary$study1$df.null\n[1] 1731\n\n$output.summary$study1$deviance.resid\n[1] 289.5664\n\n$output.summary$study1$df.resid\n[1] 1730\n\n$output.summary$study1$formula\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\n\n$output.summary$study1$family\n\nFamily: gaussian \nLink function: identity \n\n\n$output.summary$study1$coefficients\n                       Estimate  Std. Error   t value      Pr(&gt;|t|)\n(Intercept)          1.86092195 0.056114010 33.163232 4.254496e-187\nD$PM_BMI_CONTINUOUS -0.01053625 0.002017893 -5.221413  1.990047e-07\n\n\n$output.summary$study2\n$output.summary$study2$rank\n[1] 2\n\n$output.summary$study2$aic\n[1] 2662.953\n\n$output.summary$study2$iter\n[1] 2\n\n$output.summary$study2$converged\n[1] TRUE\n\n$output.summary$study2$boundary\n[1] FALSE\n\n$output.summary$study2$na.action\n$output.summary$study2$na.action$na.action\n[1] \"na.omit\"\n\n\n$output.summary$study2$call\nglm(formula = formula, family = gaussian, x = TRUE)\n\n$output.summary$study2$terms\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\nattr(,\"variables\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"factors\")\n                    D$PM_BMI_CONTINUOUS\nD$LAB_HDL                             0\nD$PM_BMI_CONTINUOUS                   1\nattr(,\"term.labels\")\n[1] \"D$PM_BMI_CONTINUOUS\"\nattr(,\"order\")\n[1] 1\nattr(,\"intercept\")\n[1] 1\nattr(,\"response\")\n[1] 1\nattr(,\".Environment\")\n&lt;environment: R_GlobalEnv&gt;\nattr(,\"predvars\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"dataClasses\")\n          D$LAB_HDL D$PM_BMI_CONTINUOUS \n          \"numeric\"           \"numeric\" \n\n$output.summary$study2$contrasts\nNULL\n\n$output.summary$study2$aliased\n        (Intercept) D$PM_BMI_CONTINUOUS \n              FALSE               FALSE \n\n$output.summary$study2$dispersion\n[1] 0.1747223\n\n$output.summary$study2$data\nNULL\n\n$output.summary$study2$df\n[1]    2 2430    2\n\n$output.summary$study2$Ntotal\n[1] 3088\n\n$output.summary$study2$Nvalid\n[1] 2432\n\n$output.summary$study2$Nmissing\n[1] 656\n\n$output.summary$study2$cov.unscaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          0.0137537512       -4.863169e-04\nD$PM_BMI_CONTINUOUS -0.0004863169        1.772554e-05\n\n$output.summary$study2$cov.scaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          2.403088e-03       -8.497043e-05\nD$PM_BMI_CONTINUOUS -8.497043e-05        3.097047e-06\n\n$output.summary$study2$offset\nNULL\n\n$output.summary$study2$weights\nNULL\n\n$output.summary$study2$VarCovMatrix\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          2.403088e-03       -8.497043e-05\nD$PM_BMI_CONTINUOUS -8.497043e-05        3.097047e-06\n\n$output.summary$study2$CorrMatrix\n           [,1]       [,2]\n[1,]  1.0000000 -0.9849385\n[2,] -0.9849385  1.0000000\n\n$output.summary$study2$deviance.null\n[1] 433.1644\n\n$output.summary$study2$df.null\n[1] 2431\n\n$output.summary$study2$deviance.resid\n[1] 424.5753\n\n$output.summary$study2$df.resid\n[1] 2430\n\n$output.summary$study2$formula\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\n\n$output.summary$study2$family\n\nFamily: gaussian \nLink function: identity \n\n\n$output.summary$study2$coefficients\n                       Estimate  Std. Error   t value      Pr(&gt;|t|)\n(Intercept)          1.89602432 0.049021297 38.677563 1.934321e-255\nD$PM_BMI_CONTINUOUS -0.01233882 0.001759843 -7.011321  3.047241e-12\n\n\n$output.summary$study3\n$output.summary$study3$rank\n[1] 2\n\n$output.summary$study3$aic\n[1] 3650.688\n\n$output.summary$study3$iter\n[1] 2\n\n$output.summary$study3$converged\n[1] TRUE\n\n$output.summary$study3$boundary\n[1] FALSE\n\n$output.summary$study3$na.action\n$output.summary$study3$na.action$na.action\n[1] \"na.omit\"\n\n\n$output.summary$study3$call\nglm(formula = formula, family = gaussian, x = TRUE)\n\n$output.summary$study3$terms\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\nattr(,\"variables\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"factors\")\n                    D$PM_BMI_CONTINUOUS\nD$LAB_HDL                             0\nD$PM_BMI_CONTINUOUS                   1\nattr(,\"term.labels\")\n[1] \"D$PM_BMI_CONTINUOUS\"\nattr(,\"order\")\n[1] 1\nattr(,\"intercept\")\n[1] 1\nattr(,\"response\")\n[1] 1\nattr(,\".Environment\")\n&lt;environment: R_GlobalEnv&gt;\nattr(,\"predvars\")\nlist(D$LAB_HDL, D$PM_BMI_CONTINUOUS)\nattr(,\"dataClasses\")\n          D$LAB_HDL D$PM_BMI_CONTINUOUS \n          \"numeric\"           \"numeric\" \n\n$output.summary$study3$contrasts\nNULL\n\n$output.summary$study3$aliased\n        (Intercept) D$PM_BMI_CONTINUOUS \n              FALSE               FALSE \n\n$output.summary$study3$dispersion\n[1] 0.1755542\n\n$output.summary$study3$data\nNULL\n\n$output.summary$study3$df\n[1]    2 3319    2\n\n$output.summary$study3$Ntotal\n[1] 4128\n\n$output.summary$study3$Nvalid\n[1] 3321\n\n$output.summary$study3$Nmissing\n[1] 807\n\n$output.summary$study3$cov.unscaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          0.0101483757       -3.600539e-04\nD$PM_BMI_CONTINUOUS -0.0003600539        1.316496e-05\n\n$output.summary$study3$cov.scaled\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          1.781590e-03       -6.320896e-05\nD$PM_BMI_CONTINUOUS -6.320896e-05        2.311164e-06\n\n$output.summary$study3$offset\nNULL\n\n$output.summary$study3$weights\nNULL\n\n$output.summary$study3$VarCovMatrix\n                      (Intercept) D$PM_BMI_CONTINUOUS\n(Intercept)          1.781590e-03       -6.320896e-05\nD$PM_BMI_CONTINUOUS -6.320896e-05        2.311164e-06\n\n$output.summary$study3$CorrMatrix\n           [,1]       [,2]\n[1,]  1.0000000 -0.9850527\n[2,] -0.9850527  1.0000000\n\n$output.summary$study3$deviance.null\n[1] 595.2469\n\n$output.summary$study3$df.null\n[1] 3320\n\n$output.summary$study3$deviance.resid\n[1] 582.6643\n\n$output.summary$study3$df.resid\n[1] 3319\n\n$output.summary$study3$formula\nD$LAB_HDL ~ D$PM_BMI_CONTINUOUS\n\n$output.summary$study3$family\n\nFamily: gaussian \nLink function: identity \n\n\n$output.summary$study3$coefficients\n                       Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept)          1.92915714 0.042208881 45.705005 0.000000e+00\nD$PM_BMI_CONTINUOUS -0.01287048 0.001520251 -8.466023 3.758072e-17\n\n\n$output.summary$input.beta.matrix.for.SLMA\n                    betas study 1 betas study 2 betas study 3\n(Intercept)            1.86092195    1.89602432    1.92915714\nD$PM_BMI_CONTINUOUS   -0.01053625   -0.01233882   -0.01287048\n\n$output.summary$input.se.matrix.for.SLMA\n                    ses study 1 ses study 2 ses study 3\n(Intercept)         0.056114010 0.049021297 0.042208881\nD$PM_BMI_CONTINUOUS 0.002017893 0.001759843 0.001520251\n\n\n$num.valid.studies\n[1] 3\n\n$betamatrix.all\n                    betas study 1 betas study 2 betas study 3\n(Intercept)            1.86092195    1.89602432    1.92915714\nD$PM_BMI_CONTINUOUS   -0.01053625   -0.01233882   -0.01287048\n\n$sematrix.all\n                    ses study 1 ses study 2 ses study 3\n(Intercept)         0.056114010 0.049021297 0.042208881\nD$PM_BMI_CONTINUOUS 0.002017893 0.001759843 0.001520251\n\n$betamatrix.valid\n                    betas study 1 betas study 2 betas study 3\n(Intercept)            1.86092195    1.89602432    1.92915714\nD$PM_BMI_CONTINUOUS   -0.01053625   -0.01233882   -0.01287048\n\n$sematrix.valid\n                    ses study 1 ses study 2 ses study 3\n(Intercept)         0.056114010 0.049021297 0.042208881\nD$PM_BMI_CONTINUOUS 0.002017893 0.001759843 0.001520251\n\n$SLMA.pooled.ests.matrix\n                      pooled.ML        se.ML pooled.REML      se.REML\n(Intercept)          1.90177672 0.0277883839  1.90177672 0.0277883839\nD$PM_BMI_CONTINUOUS -0.01212642 0.0009994221 -0.01212642 0.0009994221\n                      pooled.FE        se.FE\n(Intercept)          1.90177672 0.0277883839\nD$PM_BMI_CONTINUOUS -0.01212642 0.0009994221\n\n$is.object.created\n[1] \"A data object &lt;workshop.obj&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;workshop.obj&gt; appears valid in all sources\"\n\n\nFor the SLMA approach we can assign the predicted values at each study:\n\nds.glmPredict(glmname = \"workshop.obj\", newobj = \"workshop.prediction.obj\", datasources = connections)\n\n$study1\n$study1$safe.list\n$study1$safe.list$glm.object\n[1] \"workshop.obj\"\n\n$study1$safe.list$newdfname\nNULL\n\n$study1$safe.list$output.type\n[1] \"response\"\n\n$study1$safe.list$dispersion\nNULL\n\n$study1$safe.list$fit.Ntotal\n[1] 1732\n\n$study1$safe.list$fit.Nvalid\n[1] 1732\n\n$study1$safe.list$fit.Nmiss\n[1] 0\n\n$study1$safe.list$fit.mean\n[1] 1.572459\n\n$study1$safe.list$fit.sd\n[1] 0.2265924\n\n$study1$safe.list$fit.quantiles\n      5%      10%      25%      50%      75%      90%      95% \n1.488919 1.505439 1.538276 1.572387 1.605839 1.637659 1.655455 \n\n\n\n$study2\n$study2$safe.list\n$study2$safe.list$glm.object\n[1] \"workshop.obj\"\n\n$study2$safe.list$newdfname\nNULL\n\n$study2$safe.list$output.type\n[1] \"response\"\n\n$study2$safe.list$dispersion\nNULL\n\n$study2$safe.list$fit.Ntotal\n[1] 2432\n\n$study2$safe.list$fit.Nvalid\n[1] 2432\n\n$study2$safe.list$fit.Nmiss\n[1] 0\n\n$study2$safe.list$fit.mean\n[1] 1.557497\n\n$study2$safe.list$fit.sd\n[1] 0.243804\n\n$study2$safe.list$fit.quantiles\n      5%      10%      25%      50%      75%      90%      95% \n1.460655 1.481193 1.518580 1.557941 1.596839 1.633442 1.655954 \n\n\n\n$study3\n$study3$safe.list\n$study3$safe.list$glm.object\n[1] \"workshop.obj\"\n\n$study3$safe.list$newdfname\nNULL\n\n$study3$safe.list$output.type\n[1] \"response\"\n\n$study3$safe.list$dispersion\nNULL\n\n$study3$safe.list$fit.Ntotal\n[1] 3321\n\n$study3$safe.list$fit.Nvalid\n[1] 3321\n\n$study3$safe.list$fit.Nmiss\n[1] 0\n\n$study3$safe.list$fit.mean\n[1] 1.577157\n\n$study3$safe.list$fit.sd\n[1] 0.2481178\n\n$study3$safe.list$fit.quantiles\n      5%      10%      25%      50%      75%      90%      95% \n1.477918 1.499540 1.535707 1.576635 1.618592 1.654372 1.679084 \n\nds.length(\"workshop.prediction.obj$fit\", datasources=connections)\n\n$`length of workshop.prediction.obj$fit in study1`\n[1] 1732\n\n$`length of workshop.prediction.obj$fit in study2`\n[1] 2432\n\n$`length of workshop.prediction.obj$fit in study3`\n[1] 3321\n\n$`total length of workshop.prediction.obj$fit in all studies combined`\n[1] 7485\n\nds.length(\"D$LAB_HDL\", datasources=connections)\n\n$`length of D$LAB_HDL in study1`\n[1] 2163\n\n$`length of D$LAB_HDL in study2`\n[1] 3088\n\n$`length of D$LAB_HDL in study3`\n[1] 4128\n\n$`total length of D$LAB_HDL in all studies combined`\n[1] 9379\n\n\n\nds.cbind(c('D$LAB_HDL', 'D$PM_BMI_CONTINUOUS'), newobj='vars')\n\n$is.object.created\n[1] \"A data object &lt;vars&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;vars&gt; appears valid in all sources\"\n\nds.completeCases('vars', newobj='vars.complete')\n\n$is.object.created\n[1] \"A data object &lt;vars.complete&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;vars.complete&gt; appears valid in all sources\"\n\nds.dim('vars.complete')\n\n$`dimensions of vars.complete in study1`\n[1] 1732    2\n\n$`dimensions of vars.complete in study2`\n[1] 2432    2\n\n$`dimensions of vars.complete in study3`\n[1] 3321    2\n\n$`dimensions of vars.complete in combined studies`\n[1] 7485    2\n\n\nLet’s plot the best linear fit on a scatter plot\n\ndf1 &lt;- ds.scatterPlot('D$PM_BMI_CONTINUOUS', \"D$LAB_HDL\", datasources = connections, return.coords = TRUE)\ndf2 &lt;- ds.scatterPlot('vars.complete$PM_BMI_CONTINUOUS', \"workshop.prediction.obj$fit\", datasources = connections, return.coords = TRUE)\n\n\n\n\n\n\n\n# then in native R\npar(mfrow=c(2,2))\n\n\n\n\n\n\n\nplot(as.data.frame(df1[[1]][[1]])$x,as.data.frame(df1[[1]][[1]])$y, xlab='Body Mass Index', ylab='HDL Cholesterol', main='Study 1')\nlines(as.data.frame(df2[[1]][[1]])$x,as.data.frame(df2[[1]][[1]])$y, col='red')\nplot(as.data.frame(df1[[1]][[2]])$x,as.data.frame(df1[[1]][[2]])$y, xlab='Body Mass Index', ylab='HDL Cholesterol', main='Study 2')\nlines(as.data.frame(df2[[1]][[2]])$x,as.data.frame(df2[[1]][[2]])$y, col='red')\nplot(as.data.frame(df1[[1]][[3]])$x,as.data.frame(df1[[1]][[3]])$y, xlab='Body Mass Index', ylab='HDL Cholesterol', main='Study 3')\nlines(as.data.frame(df2[[1]][[3]])$x,as.data.frame(df2[[1]][[3]])$y, col='red')\n\n\n\n\n\n\n\n\nFor the SLMA approach we can also create the predicted values and the residuals at each study using the ds.make function:\n\nglmslma &lt;- ds.glmSLMA(formula = \"vars.complete$LAB_HDL~vars.complete$PM_BMI_CONTINUOUS\", family=\"gaussian\", newobj = \"workshop.obj\", datasources = connections)\n\nds.make(toAssign=paste0(\"(\",glmslma$SLMA.pooled.ests.matrix[1,1],\")+(\", glmslma$SLMA.pooled.ests.matrix[2,1],\"*vars.complete$PM_BMI_CONTINUOUS)\"), \n        newobj = \"predicted.values\")\n\n$is.object.created\n[1] \"A data object &lt;predicted.values&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;predicted.values&gt; appears valid in all sources\"\n\nds.make(toAssign = \"vars.complete$LAB_HDL - predicted.values\", \n        newobj = \"residuals\")\n\n$is.object.created\n[1] \"A data object &lt;residuals&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;residuals&gt; appears valid in all sources\"\n\n# and you can use those to run regression plot diagnostics  \nds.scatterPlot('predicted.values', \"residuals\", datasources = connections)\n\n[1] \"Split plot created\"\n\nds.histogram(\"residuals\", datasources = connections)\n\n\n\n\n\n\n\n\nWarning: study1: 1 invalid cells\n\n\nWarning: study2: 0 invalid cells\n\n\nWarning: study3: 1 invalid cells\n\n\n[[1]]\n$breaks\n [1] -2.137653016 -1.780801502 -1.423949988 -1.067098474 -0.710246960\n [6] -0.353395446  0.003456068  0.360307581  0.717159095  1.074010609\n[11]  1.430862123\n\n$counts\n [1]   0   0  15  63 247 516 570 256  59   5\n\n$density\n [1] 0.00000000 0.00000000 0.02426922 0.10193073 0.39963316 0.83486119\n [7] 0.92223038 0.41419470 0.09545893 0.00808974\n\n$mids\n [1] -1.9592273 -1.6023757 -1.2455242 -0.8886727 -0.5318212 -0.1749697\n [7]  0.1818818  0.5387333  0.8955849  1.2524364\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[2]]\n$breaks\n [1] -2.137653016 -1.780801502 -1.423949988 -1.067098474 -0.710246960\n [6] -0.353395446  0.003456068  0.360307581  0.717159095  1.074010609\n[11]  1.430862123\n\n$counts\n [1]   0   5  17  96 364 751 752 353  84  10\n\n$density\n [1] 0.000000000 0.005761279 0.019588348 0.110616552 0.419421095 0.865344072\n [7] 0.866496328 0.406746281 0.096789483 0.011522558\n\n$mids\n [1] -1.9592273 -1.6023757 -1.2455242 -0.8886727 -0.5318212 -0.1749697\n [7]  0.1818818  0.5387333  0.8955849  1.2524364\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n[[3]]\n$breaks\n [1] -2.137653016 -1.780801502 -1.423949988 -1.067098474 -0.710246960\n [6] -0.353395446  0.003456068  0.360307581  0.717159095  1.074010609\n[11]  1.430862123\n\n$counts\n [1]    0    7   29  106  488  975 1068  518  121    8\n\n$density\n [1] 0.000000000 0.005906655 0.024470429 0.089443636 0.411778249 0.822712691\n [7] 0.901186824 0.437092486 0.102100754 0.006750463\n\n$mids\n [1] -1.9592273 -1.6023757 -1.2455242 -0.8886727 -0.5318212 -0.1749697\n [7]  0.1818818  0.5387333  0.8955849  1.2524364\n\n$xname\n[1] \"xvect\"\n\n$equidist\n[1] TRUE\n\nattr(,\"class\")\n[1] \"histogram\"\n\n\n\n\n\n\n\n\n\n\n\nCreating forest plots\nWe want to examine the relationship between BMI and diabetes\nExamine the distribution of the variable “DIS_DIAB” in all cohorts using ‘ds.table’:\n\nds.table(\"D$DIS_DIAB\")\n\n\n Data in all studies were valid \n\nStudy 1 :  No errors reported from this study\nStudy 2 :  No errors reported from this study\nStudy 3 :  No errors reported from this study\n\n\n$output.list\n$output.list$TABLE_rvar.by.study_row.props\n          study\nD$DIS_DIAB    study1    study2    study3\n        0  0.2310192 0.3293621 0.4396188\n        1  0.2054795 0.3219178 0.4726027\n        NA       NaN       NaN       NaN\n\n$output.list$TABLE_rvar.by.study_col.props\n          study\nD$DIS_DIAB     study1     study2     study3\n        0  0.98613037 0.98477979 0.98328488\n        1  0.01386963 0.01522021 0.01671512\n        NA 0.00000000 0.00000000 0.00000000\n\n$output.list$TABLE_rvar.by.study_counts\n          study\nD$DIS_DIAB study1 study2 study3\n        0    2133   3041   4059\n        1      30     47     69\n        NA      0      0      0\n\n$output.list$TABLES.COMBINED_all.sources_proportions\nD$DIS_DIAB\n     0      1     NA \n0.9840 0.0156 0.0000 \n\n$output.list$TABLES.COMBINED_all.sources_counts\nD$DIS_DIAB\n   0    1   NA \n9233  146    0 \n\n\n$validity.message\n[1] \"Data in all studies were valid\"\n\n\nCheck the class of “DIS_DIAB”:\n\nds.class(\"D$DIS_DIAB\")\n\n$study1\n[1] \"factor\"\n\n$study2\n[1] \"factor\"\n\n$study3\n[1] \"factor\"\n\n\nExamine the association between BMI and diabetes:\n\nglmSLMA_mod2&lt;-ds.glmSLMA(formula=\"D$DIS_DIAB~D$PM_BMI_CONTINUOUS\", family='binomial')\n\nSave effect estimates and standard errors as new objects\n\nestimates &lt;- c(glmSLMA_mod2$betamatrix.valid[2,])\nse &lt;- c(glmSLMA_mod2$sematrix.valid[2,])\n\nMeta-analyse the results using rma to obtain study weights:\n\nres &lt;- rma(estimates, sei=se)\n\nCan produce simple forest plots using output:\n\nforest(res, atransf=exp)\n\n\n\n\n\n\n\n\nWe can also add more information to forest plots:\n\nstudy_names &lt;- c(\"study 1\", \"study 2\", \"study 3\")\nweights &lt;-  c(paste0(formatC(weights(res), format=\"f\", digits=1, width=4), \"%\"))\n\nforest(res, atransf=exp,\n       xlab=\"Crude Odds Ratio\", refline=log(1), xlim=c(-0.25,0.5), at=log(c(0.95, 1, 1.1, 1.2, 1.3)),\n       slab=cbind(paste0(study_names, \" (\", paste0(weights, \")\"))), mlab=\"RE model\")\ntext(0.5, 4.5, pos=2, \"Odds Ratio [95% CI]\")\ntext(-0.25, 4.5, pos=4, \"Study (weight)\")\n\n\n\n\n\n\n\n\n\n\nModelling multiple variables and interactions\nAlso possible to model multiple explanatory variables and include interactions:\n\nglm_mod1&lt;-ds.glm(formula=\"D$DIS_DIAB~D$PM_BMI_CONTINUOUS+D$LAB_HDL*D$GENDER\", family='binomial', datasources = connections)\n\nIteration 1...\n\n\nCURRENT DEVIANCE:      10376.4132929824\n\n\nIteration 2...\n\n\nCURRENT DEVIANCE:      2404.18978205835\n\n\nIteration 3...\n\n\nCURRENT DEVIANCE:      1357.74614354854\n\n\nIteration 4...\n\n\nCURRENT DEVIANCE:      1095.98897339272\n\n\nIteration 5...\n\n\nCURRENT DEVIANCE:      1040.08118737452\n\n\nIteration 6...\n\n\nCURRENT DEVIANCE:      1033.57954875967\n\n\nIteration 7...\n\n\nCURRENT DEVIANCE:      1033.4312300543\n\n\nIteration 8...\n\n\nCURRENT DEVIANCE:      1033.43112377231\n\n\nIteration 9...\n\n\nCURRENT DEVIANCE:      1033.43112377224\n\n\nSUMMARY OF MODEL STATE after iteration 9\n\n\nCurrent deviance 1033.43112377224 on 7480 degrees of freedom\n\n\nConvergence criterion TRUE (6.2259131505956e-14)\n\n\n\nbeta: -6.42274546317614 0.129428314189867 -0.99120070335343 -1.56103433048665 0.797170506403169\n\n\n\nInformation matrix overall:\n\n\n                    (Intercept) D$PM_BMI_CONTINUOUS  D$LAB_HDL  D$GENDER1\n(Intercept)           101.99761            3121.043  140.68963   34.51419\nD$PM_BMI_CONTINUOUS  3121.04300           97856.576 4265.77262 1022.78959\nD$LAB_HDL             140.68963            4265.773  217.08906   54.66413\nD$GENDER1              34.51419            1022.790   54.66413   34.51419\nD$LAB_HDL:D$GENDER1    54.66413            1614.821   92.09369   54.66413\n                    D$LAB_HDL:D$GENDER1\n(Intercept)                    54.66413\nD$PM_BMI_CONTINUOUS          1614.82140\nD$LAB_HDL                      92.09369\nD$GENDER1                      54.66413\nD$LAB_HDL:D$GENDER1            92.09369\n\n\n\nScore vector overall:\n\n\n                             [,1]\n(Intercept)         -3.006395e-11\nD$PM_BMI_CONTINUOUS -7.926246e-10\nD$LAB_HDL           -5.252776e-11\nD$GENDER1           -2.325873e-11\nD$LAB_HDL:D$GENDER1 -4.320544e-11\n\n\n\nCurrent deviance: 1033.43112377224\n\n\nThe “*” between LAB_HDL and GENDER means fit all possible main effects and interactions between the two covariates.\nCompare with results of a study-level meta analysis:\n\nglmSLMA_mod2&lt;-ds.glmSLMA(formula=\"D$DIS_DIAB~D$PM_BMI_CONTINUOUS+D$LAB_HDL*D$GENDER\", family='binomial')\n\nNow compare outputs:\n\nglm_mod1$coefficients\n\n                      Estimate Std. Error   z-value      p-value low0.95CI.LP\n(Intercept)         -6.4227455 0.77703028 -8.265760 1.388081e-16  -7.94569683\nD$PM_BMI_CONTINUOUS  0.1294283 0.02101243  6.159607 7.292573e-10   0.08824471\nD$LAB_HDL           -0.9912007 0.25745856 -3.849943 1.181455e-04  -1.49581021\nD$GENDER1           -1.5610343 0.77864285 -2.004814 4.498290e-02  -3.08714627\nD$LAB_HDL:D$GENDER1  0.7971705 0.49668192  1.604992 1.084956e-01  -0.17630817\n                    high0.95CI.LP        P_OR low0.95CI.P_OR high0.95CI.P_OR\n(Intercept)           -4.89979410 0.001621557   0.0003540576     0.007393052\nD$PM_BMI_CONTINUOUS    0.17061192 1.138177517   1.0922553714     1.186030387\nD$LAB_HDL             -0.48659119 0.371130805   0.2240669893     0.614718282\nD$GENDER1             -0.03492239 0.209918833   0.0456319902     0.965680359\nD$LAB_HDL:D$GENDER1    1.77064918 2.219252675   0.8383595883     5.874665842\n\nglmSLMA_mod2$SLMA.pooled.ests.matrix\n\n                     pooled.ML      se.ML pooled.REML    se.REML  pooled.FE\n(Intercept)         -6.4534338 0.78157668  -6.4534338 0.78157668 -6.4534338\nD$PM_BMI_CONTINUOUS  0.1291349 0.02114524   0.1291349 0.02114524  0.1291349\nD$LAB_HDL           -0.9873823 0.25787450  -0.9873823 0.25787450 -0.9873823\nD$GENDER1           -1.5166315 0.78378855  -1.5166315 0.78378855 -1.5166315\nD$LAB_HDL:D$GENDER1  0.7738504 0.49963906   0.7738504 0.49963906  0.7738504\n                         se.FE\n(Intercept)         0.78157668\nD$PM_BMI_CONTINUOUS 0.02114524\nD$LAB_HDL           0.25787450\nD$GENDER1           0.78378855\nD$LAB_HDL:D$GENDER1 0.49963906\n\n\nSimilar, but differences between the results are accounted for by the different techniques employed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/datashield.html#at-the-end-of-your-rstudio-server-analysis",
    "href": "chapters/datashield.html#at-the-end-of-your-rstudio-server-analysis",
    "title": "DataSHIELD Workshop",
    "section": "At the end of your RStudio Server analysis:",
    "text": "At the end of your RStudio Server analysis:\nYou can save your workspace:\n\nDSI::datashield.workspace_save(conns = connections, ws = \"workspace2025\")\n\nDon’t forget to log out! Using:\n\nDSI::datashield.logout(connections)\n\nYou can restore your workspace, the next time you want to continue with your analysis\n\nconnections &lt;- datashield.login(logins = logindata, assign = TRUE, symbol = \"D\")\n\n\nLogging into the collaborating servers\n\n\n\n  No variables have been specified. \n  All the variables in the table \n  (the whole dataset) will be assigned to R!\n\n\n\nAssigning table data...\n\nds.ls()\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n[1] \"D\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n[1] \"D\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n[1] \"D\"\n\ndatashield.logout(connections)\n\nconnections &lt;- datashield.login(logins = logindata, restore = \"workspace2025\")\n\n\nLogging into the collaborating servers\n\nds.ls()\n\n$study1\n$study1$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study1$objects.found\n [1] \"BMI.25.plus\"             \"BMI.25.plus_GLUC.6.less\"\n [3] \"CNSIM.subset.Females\"    \"CNSIM.subset.Males\"     \n [5] \"D\"                       \"D_without_NA\"           \n [7] \"D2\"                      \"df_rename\"              \n [9] \"df_subset\"               \"DIS_DIAB\"               \n[11] \"GENDER\"                  \"GLUC.6.less\"            \n[13] \"LAB_HDL\"                 \"LAB_HDL_log\"            \n[15] \"LAB_HDL_sqrt\"            \"new.glm.obj\"            \n[17] \"ONES\"                    \"PM_BMI_CONTINUOUS\"      \n[19] \"predicted.values\"        \"residuals\"              \n[21] \"subset.BMI.25.plus\"      \"subset2\"                \n[23] \"vars\"                    \"vars.complete\"          \n[25] \"workshop.obj\"            \"workshop.prediction.obj\"\n\n\n$study2\n$study2$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study2$objects.found\n [1] \"BMI.25.plus\"             \"BMI.25.plus_GLUC.6.less\"\n [3] \"CNSIM.subset.Females\"    \"CNSIM.subset.Males\"     \n [5] \"D\"                       \"D_without_NA\"           \n [7] \"D2\"                      \"df_rename\"              \n [9] \"df_subset\"               \"DIS_DIAB\"               \n[11] \"GENDER\"                  \"GLUC.6.less\"            \n[13] \"LAB_HDL\"                 \"LAB_HDL_log\"            \n[15] \"LAB_HDL_sqrt\"            \"new.glm.obj\"            \n[17] \"ONES\"                    \"PM_BMI_CONTINUOUS\"      \n[19] \"predicted.values\"        \"residuals\"              \n[21] \"subset.BMI.25.plus\"      \"subset2\"                \n[23] \"vars\"                    \"vars.complete\"          \n[25] \"workshop.obj\"            \"workshop.prediction.obj\"\n\n\n$study3\n$study3$environment.searched\n[1] \"R_GlobalEnv\"\n\n$study3$objects.found\n [1] \"BMI.25.plus\"             \"BMI.25.plus_GLUC.6.less\"\n [3] \"CNSIM.subset.Females\"    \"CNSIM.subset.Males\"     \n [5] \"D\"                       \"D_without_NA\"           \n [7] \"D2\"                      \"df_rename\"              \n [9] \"df_subset\"               \"DIS_DIAB\"               \n[11] \"GENDER\"                  \"GLUC.6.less\"            \n[13] \"LAB_HDL\"                 \"LAB_HDL_log\"            \n[15] \"LAB_HDL_sqrt\"            \"new.glm.obj\"            \n[17] \"ONES\"                    \"PM_BMI_CONTINUOUS\"      \n[19] \"predicted.values\"        \"residuals\"              \n[21] \"subset.BMI.25.plus\"      \"subset2\"                \n[23] \"vars\"                    \"vars.complete\"          \n[25] \"workshop.obj\"            \"workshop.prediction.obj\"\n\n\nAlso you can delete unwanted workspaces using the datashield.workspace_rm\nIn Rstudio Server: DON’T forget to use the orange “quit the current R session” button (top right of browser screen) before closing the tab- otherwise you will experience an error message the next time you try to log in.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>DataSHIELD Workshop</span>"
    ]
  },
  {
    "objectID": "chapters/dsomop.html",
    "href": "chapters/dsomop.html",
    "title": "dsOMOP COPD Example",
    "section": "",
    "text": "Libraries\n\nlibrary(DSI)\nlibrary(DSOpal)\nlibrary(dsBaseClient)\nlibrary(dsOMOPClient)\nlibrary(dsOMOPHelper)\n\n\n\nConnection\n\nbuilder &lt;- newDSLoginBuilder()\nbuilder$append(server=\"opal-demo\",\n              url=\"https://opal-demo.obiba.org/\",\n              user=\"dsuser\",\n              password=\"P@ssw0rd\",\n              driver = \"OpalDriver\",\n              profile = \"omop\")\n\nlogindata &lt;- builder$build()\nconns &lt;- datashield.login(logins=logindata)\n\n\nLogging into the collaborating servers\n\n\n\n\nSetup\n\no &lt;- ds.omop.helper(\n    connections = conns,\n    resource = \"omop_demo.mimiciv\", \n    symbol = \"mimiciv\"\n)\n\n\n\nData retrieval\n\n# Define concept IDs\nconcepts &lt;- list(\n    outcome = 255573,      # Chronic obstructive lung diease (condition)\n    predictor1 = 4005823,  # Tobacco use (observation)\n    predictor2 = 317009    # Asthma (condition)\n)\n\n# Get data\no$auto(\n    table = \"condition_occurrence\", \n    concepts = c(concepts$outcome, concepts$predictor2),\n    columns = c(\"condition_occurrence_id\")\n)\n\no$auto(\n    table = \"observation\", \n    concepts = concepts$predictor1,\n    columns = c(\"observation_id\")\n)\n\n\n\nData preparation\n\n# Convert variables to boolean\nfor (var in c(\"tobacco_user\", \"asthma\", \"chronic_obstructive_lung_disease\")) {\n    id_type &lt;- if(var == \"tobacco_user\") \"observation_id\" else \"condition_occurrence_id\"\n    full_var &lt;- paste0(\"mimiciv$\", var, \".\", id_type)\n    \n    # Convert to numeric\n    ds.asNumeric(x.name = full_var, newobj = paste0(var, \"_num\"), datasources = conns)\n    \n    # Convert to boolean\n    ds.Boole(V1 = paste0(var, \"_num\"), V2 = 0, Boolean.operator = \"!=\", \n             numeric.output = TRUE, na.assign = 0, newobj = var)\n}\n\n# Create analysis table\nds.cbind(\n    x = c(\"chronic_obstructive_lung_disease\", \"tobacco_user\", \"asthma\"),\n    DataSHIELD.checks = FALSE,\n    newobj = \"analysis_table\",\n    datasources = conns\n)\n\n$is.object.created\n[1] \"A data object &lt;analysis_table&gt; has been created in all specified data sources\"\n\n$validity.check\n[1] \"&lt;analysis_table&gt; appears valid in all sources\"\n\n\n\n\nAnalysis\n\nmodel &lt;- ds.glm(\n    formula = \"chronic_obstructive_lung_disease ~ tobacco_user + asthma\", \n    data = \"analysis_table\", \n    family = \"binomial\"\n)\n\nIteration 1...\n\n\nCURRENT DEVIANCE:      138.629436111989\n\n\nIteration 2...\n\n\nCURRENT DEVIANCE:      78.0590708707556\n\n\nIteration 3...\n\n\nCURRENT DEVIANCE:      74.7467187767252\n\n\nIteration 4...\n\n\nCURRENT DEVIANCE:      74.2030114578086\n\n\nIteration 5...\n\n\nCURRENT DEVIANCE:      74.0233507082636\n\n\nIteration 6...\n\n\nCURRENT DEVIANCE:      73.9585499903207\n\n\nIteration 7...\n\n\nCURRENT DEVIANCE:      73.9348750862782\n\n\nIteration 8...\n\n\nCURRENT DEVIANCE:      73.9261875543204\n\n\nIteration 9...\n\n\nCURRENT DEVIANCE:      73.9229945562601\n\n\nIteration 10...\n\n\nCURRENT DEVIANCE:      73.9218203189776\n\n\nIteration 11...\n\n\nCURRENT DEVIANCE:      73.9213883954805\n\n\nIteration 12...\n\n\nCURRENT DEVIANCE:      73.9212295070478\n\n\nIteration 13...\n\n\nCURRENT DEVIANCE:      73.9211710562536\n\n\nIteration 14...\n\n\nCURRENT DEVIANCE:      73.9211495535426\n\n\nIteration 15...\n\n\nCURRENT DEVIANCE:      73.9211416431554\n\n\nIteration 16...\n\n\nCURRENT DEVIANCE:      73.9211387330891\n\n\nIteration 17...\n\n\nCURRENT DEVIANCE:      73.9211376625358\n\n\nIteration 18...\n\n\nCURRENT DEVIANCE:      73.9211372687014\n\n\nSUMMARY OF MODEL STATE after iteration 18\n\n\nCurrent deviance 73.9211372687014 on 97 degrees of freedom\n\n\nConvergence criterion TRUE (5.32056746705131e-09)\n\n\n\nbeta: -1.84582669049832 1.15267950993838 -17.5489136601271\n\n\n\nInformation matrix overall:\n\n\n              (Intercept) tobacco_user       asthma\n(Intercept)  1.103030e+01 6.666667e-01 1.146012e-07\ntobacco_user 6.666667e-01 6.666667e-01 3.249886e-08\nasthma       1.146012e-07 3.249886e-08 1.146012e-07\n\n\n\nScore vector overall:\n\n\n                      [,1]\n(Intercept)  -1.146011e-07\ntobacco_user -3.249885e-08\nasthma       -1.146012e-07\n\n\n\nCurrent deviance: 73.9211372687014\n\nprint(model)\n\n$Nvalid\n[1] 100\n\n$Nmissing\n[1] 0\n\n$Ntotal\n[1] 100\n\n$disclosure.risk\n          RISK OF DISCLOSURE\nopal-demo                  0\n\n$errorMessage\n          ERROR MESSAGES\nopal-demo \"No errors\"   \n\n$nsubs\n[1] 100\n\n$iter\n[1] 18\n\n$family\n\nFamily: binomial \nLink function: logit \n\n\n$formula\n[1] \"chronic_obstructive_lung_disease ~ tobacco_user + asthma\"\n\n$coefficients\n               Estimate   Std. Error      z-value      p-value low0.95CI.LP\n(Intercept)   -1.845827    0.3106304 -5.942196444 2.812281e-09    -2.454651\ntobacco_user   1.152680    1.2635233  0.912274032 3.616245e-01    -1.323781\nasthma       -17.548914 2953.9650106 -0.005940799 9.952600e-01 -5807.213946\n             high0.95CI.LP         P_OR low0.95CI.P_OR high0.95CI.P_OR\n(Intercept)      -1.237002 1.363636e-01     0.07909909       0.2249582\ntobacco_user      3.629140 3.166667e+00     0.26612726      37.6803863\nasthma         5772.116119 2.391132e-08     0.00000000             Inf\n\n$dev\n[1] 73.92114\n\n$df\n[1] 97\n\n$output.information\n[1] \"SEE TOP OF OUTPUT FOR INFORMATION ON MISSING DATA AND ERROR MESSAGES\"\n\n\n\n\nLogout\n\ndatashield.logout(conns)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>dsOMOP COPD Example</span>"
    ]
  }
]